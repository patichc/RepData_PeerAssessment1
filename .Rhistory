select(cran,-(x:size))
select(cran,-(x:size))
select(cran,-(x:size))
skip()
filter(cran,package=="swirl")
filter(cran,r_version=="3.1.1",country=="US")
?Comparison
filter(cran,r_version<="3.0.2",country=="IN")
filter(cran,country=="IN"|country=="US")
filter(cran,size>100500,r_os="linux-gnu")
filter(cran,size>100500,r_os=="linux-gnu")
is.na(c(3,5,NA,10))
!is.na(c(3,5,NA,10))
filter(cran,!is.na(r_version))
cran2 <- select(cran,size:ip_id))
cran2 <- select(cran,size:ip_id)
arrange(cran2,ip_id)
arrange(cran2,desc(ip_id))
arrange(cran2,package,ip_id)
arrange(cran2,country,desc(r_version),ip_id)
cran3 <- select(cran, ip_id, package,size)
View(cran3)
cran3
mutate(cran3,size_mb=size/2^20)
mutate(cran3,size_gb=size_mb/2^10)
mutate(cran3,size_mb=size/2^20,size_gb=size_mb/2^10)
mutate(cran3,correct_size=size-1000)
mutate(cran3,correct_size=size+1000)
summarize(cran,avg_bytes = mean(size))
library(tidyr)
students
?gather
gather(students, sex, count, -grade)
students2
res <- gather(students, sex_class, count, -grade)
res <- gather(students2, sex_class, count, -grade)
res
?separate
separate(res,sex_class,c("sex","class"),"_")
separate(res,sex_class,c("sex","class"))
submit()
submit()
submit()
students3
submit()
submit()
submit()
reset()
submit()
submit()
spread()
?spread
spread()
submit()
submit()
extract_numeric("class5")
submit()
submit()
students4
submit()
submit()
submit()
passed
failed
passed <- passed %>% mutate(status="passed")
failed <- failed %>% mutate(status="failed")
bind_rows(passed,failed)
sat
submit()
submit()
Sys.get("LC_TIME")
Sys.getlocale("LC_TIME")
lybrary(lubridate)
library(lubridate)
help(package = lubridate)
today()
this_day <- today()
this_day
month(this_date)
month(this_day)
wday(this_day)
wday(this_day, label = TRUE)
this_moment <- now()
this_moment
hour(this_moment)
mydate <-ymd("1998-05-17")
my_date <-ymd("1998-05-17")
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1998 May 17")
ymd("1989 May 17")
mdy("March 12, 1975")
dmy(25081985)
ymd('192012')
ydm('1920/1/2')
ymd('1920/1/2')
dt1
ymd_hms(dt1)
hms("03:22:13")
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment,hours=8,minutes=34,secondes=55
)
update(this_moment,hours=8,minutes=34,secondes=01)
update(this_moment,hours=22,minutes=25,secondes=02)
update(this_moment,hours=8,minutes=34,seconds=55)
this_moment
this_moment <- update(this_moment,hours=20,minutes=27,seconds=50)
this_moment
nyc <- now(tzone("America/New_York"))
nyc <- now(t_zone("America/New_York"))
nyc <- now(tzone="America/New_York")
nyc
depart <- nyc + days(2)
depart
depart <- update (depart, hours=17,minutes=34)
depart
arrive <- depart + hours(15) + minutes(50)
?with_tz
arrive <- with_tz(arrive,tzone="Asia/Hong_Kong")
arrive
last_time <- mdy("June 17, 2008",tz="Singapore")
last_time
?nw_interval
?new_interval
how_long <-new(last_time,arrival)
how_long <-new_interval(last_time,arrival)
how_long <-new_interval(last_time,arrive)
as.period(how_long)
stopwatch()
bye()
source('~/DataScientist/GettingAndCleaningData/Oauth.R')
source('~/DataScientist/GettingAndCleaningData/Oauth.R')
req1 <- content(req)
source('~/DataScientist/GettingAndCleaningData/Oauth.R')
req1 <- content(req)
source('~/DataScientist/GettingAndCleaningData/Oauth.R')
content(req)
reqDF <-fromJSON(toJSON(content(req)))
source('~/DataScientist/GettingAndCleaningData/Oauth.R')
source('~/DataScientist/GettingAndCleaningData/Oauth.R')
source('~/DataScientist/GettingAndCleaningData/Oauth.R')
source('~/DataScientist/GettingAndCleaningData/Oauth.R')
source('~/DataScientist/GettingAndCleaningData/Oauth.R')
library(httr);library(httpuv);library(jsonlite)
oauth_endpoints("github")
myapp <- oauth_app("github",key = "946c21c5b09ddbc9c3c9",secret = "38c85b333a81d1bf67f33c18f0103f8fb1910320")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
# Use API
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
source('~/DataScientist/GettingAndCleaningData/Oauth.R')
source('~/DataScientist/GettingAndCleaningData/Oauth.R')
github_token
library(httr);library(httpuv)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "946c21c5b09ddbc9c3c9",
secret = "1f120355a68d7d8ffcbbb82a0c4639e3c4857bbc")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
# Use API
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
repInfo <- GET("https://api.github.com//repos/jtleek/datasharing", gtoken)
stop_for_status(repInfo)
library(jsonlite)
repInfoDF <-fromJSON(toJSON(content(repInfo)))
repInfoDF[1,1:3]
repInfoDF[1,1:2]
repInfoDF[1,1]
repInfo <- GET("https://api.github.com/repos/jtleek/datasharing", gtoken)
stop_for_status(repInfo)
repInfoDF <-fromJSON(toJSON(content(repInfo)))
repInfoDF[1,1]
repInfoDF@created_at
url = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
acs= read.csv(url)
library(RMySQL)
library(DBI)
library(RMySQL)
sqldf("select pwgtp1 from acs where AGEP < 50")
library(sqldf)
install.packages("sqldf")
library(sqldf)
library(gsubfn)
install.packages("gsubfn")
library(gsubfn)
library(sqldf)
sqldf("select pwgtp1 from acs where AGEP < 50")
source('~/DataScientist/GettingAndCleaningData/SQLpractice.R')
sqldf("select pwgtp1 from acs where AGEP < 50")
con <- url("http://biostat.jhsph.edu/~jleek/contact.html)
source('~/DataScientist/GettingAndCleaningData/HTMLpractice.R')
c(nchar(htmlcode[10],htmlcode[20],htmlcode[1=30],htmlcode[100])
nchar(c(htmlcode[10],htmlcode[20],htmlcode[1=30],htmlcode[100]))
nchar(htmlcode[10])
nchar(htmlCode[10])
nchar(htmlCode[20])
nchar(htmlCode[30])
nchar(htmlCode[100])
MyFile <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
MyFile <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for","MyFile.for")
MyDF <- read.fwf(file="MyFile.for",
widths=c(9,-5,4,-1,3,-5,4,-1,3-5,4,-1,3-5,4,-1,3),skip=4,
header = FALSE,
col.names = c("week","Nino1+2 SST", "Nino1+2 SSTA","Nino3 SST", "Nino3 SSTA","Nino34 SST", "Nino34 SSTA","Nino4 SST", "Nino4 SSTA"))
MyDF <- read.fwf(file="MyFile.for",
widths=c(-1,9,-5,4,-1,3,-5,4,-1,3-5,4,-1,3-5,4,-1,3),skip=4,
header = FALSE,
col.names = c("week","Nino1+2 SST", "Nino1+2 SSTA","Nino3 SST", "Nino3 SSTA","Nino34 SST", "Nino34 SSTA","Nino4 SST", "Nino4 SSTA"))
MyDF <- read.fwf(file="MyFile.for",
widths=c(-1,9,-5,4,-1,3,-5,4,-1,3-5,4,-1,3-5,4,-1,3),skip=4,
header = FALSE,
col.names = c("week","Nino1+2 SST", "Nino1+2 SSTA","Nino3 SST", "Nino3 SSTA","Nino34 SST", "Nino34 SSTA","Nino4 SST", "Nino4 SSTA"))
MyDF <- read.fwf(file="MyFile.for",
widths=c(-1,9,-5,4,-1,3,-5,4,-1,3-5,4,-1,3-5,4,-1,3),
skip=4,
sep = "\n",
header = FALSE,
col.names = c("week","Nino1+2 SST", "Nino1+2 SSTA","Nino3 SST", "Nino3 SSTA","Nino34 SST", "Nino34 SSTA","Nino4 SST", "Nino4 SSTA"))
MyDF <- read.fwf(file="MyFile.for",
widths=c(-1,9,-5,4,-1,3,-5,4,-1,3-5,4,-1,3-5,4,-1,3),
skip=4,
sep = "\n",
header = FALSE,
col.names = c("week","Nino1+2 SST", "Nino1+2 SSTA","Nino3 SST", "Nino3 SSTA","Nino34 SST", "Nino34 SSTA","Nino4 SST", "Nino4 SSTA"))
MyDF <- read.fwf(file="MyFile.for",
widths=c(-1,9,-5,4,-1,3,-5,4,-1,3,-5,4,-1,3,-5,4,-1,3),
skip=4,
sep = "\n",
header = FALSE,
col.names = c("week","Nino1+2 SST", "Nino1+2 SSTA","Nino3 SST", "Nino3 SSTA","Nino34 SST", "Nino34 SSTA","Nino4 SST", "Nino4 SSTA"))
MyDF <- read.fwf(file="MyFile.for",
widths=c(-1,9,-5,4,-1,3,-5,4,-1,3,-5,4,-1,3,-5,4,-1,3),
skip=10,
header = FALSE,
col.names = c("week","Nino1+2 SST", "Nino1+2 SSTA","Nino3 SST", "Nino3 SSTA","Nino34 SST", "Nino34 SSTA","Nino4 SST", "Nino4 SSTA"))
View(MyDF)
View(MyDF)
source('~/DataScientist/GettingAndCleaningData/Readpractice.R')
View(MyDF)
View(MyDF)
source('~/DataScientist/GettingAndCleaningData/Readpractice.R')
sqldf("select sum(Nino3. SST) from MyDF")
sqldf("select * from MyDF")
source('~/DataScientist/GettingAndCleaningData/Readpractice.R')
sqldf("select * from MyDF")
sqldf("select Nino3SST from MyDF")
sqldf("select 1 from MyDF")
sqldf("select 1 from 'MyDF'")
sqldf("select 1 from MyDF",drv="SQLite")
sqldf("select sum(Nino3SSt) from MyDF",drv="SQLite")
rnorm(10)
rnorm(10,1)
c(rnorm(10),rnorm(10),rnorm(10,1))
library(datasets)
data(iris)
?iris
library(datasets)
data(iris)
?iris
colMeans(iris,na.rm=TRUE)
colMeans(iris@Sepal.Length,na.rm=TRUE)
tapply(iris@Sepal.Length,iris@Species,mean,na.rm=TRUE)
iris@Species
iris[,5]
tapply(iris[,1],iris[@Species[,5],mean,na.rm=TRUE)
tapply(iris[,1],iris[,5],mean,na.rm=TRUE)
apply(iris[, 1:4], 1, mean)
apply(iris[, 1:4], 2, mean)
data(mtcars)
mtcars
tapply(mtcars$mpg, mtcars$cyl, mean)
tapply(mtcars$mpg, mtcars$cyl, mean)@4
tapply(mtcars$mpg, mtcars$cyl, mean)[1]
tapply(mtcars$mpg, mtcars$cyl, mean)[2]-tapply(mtcars$mpg, mtcars$cyl, mean)[1]
with(mtcars, tapply(mpg, cyl, mean))
with(mtcars, tapply(hp, cyl, mean))
a<-with(mtcars, tapply(hp, cyl, mean))
a@4
a[1]
a[3]-a[1]
source('~/.active-rstudio-document')
a<- makeVector()
numeric*()
numeric()
a@set
a[1]
a[3]
solve
makeVector(c(1,2,3,4,5))
M1 <- matrix(c(1,2,2,1,3,3,2,4,4),3,3)
solve(M1)
solve(M1+m1)
solve(M1+M1)
M1 <- matrix(c(1,2,2,1,3,5,2,4,5),3,3)
solve(M1+M1)
solve(M1)
M2 <- solve(M1)
solve(M2)
M1 == solve(M2)
M2
M1
solve(M2)
M1 == solve(M2)
M1[1,] == solve(M2)[1,]
M1[1,1] == solve(M2)[1,1]
M1[1,1]
solve(M2)[1,1]
M3 <- matrix(c(1,2,1,1,5,5,2,4,5),3,3)
M4 <-solve(M3)
M1+M3
a <- makeVector(c(1,2,3,4,5))
a
a <- cachemean(makeVector(c(1,2,3,4,5)))
source('~/.active-rstudio-document')
a <- cachemean(makeVector(c(1,2,3,4,5)))
a
a <- cachemean(makeVector(c(1,2,3,4,5)))
a <- cachemean(makeVector(c(1,2,3,4,5)))
a <- cachemean(makeVector(c(1,2,3,4,6)))
a
m
a <- cachemean(c(1,2,3,4,6))
a <- cachemean(makeVector(c(1,3,3,4,6)))
a
a<-c(1,2,3,4,5,6,7,8,9)
b <- cachemean(makeVector(a))
a
b
debug(cachemean(makeVector(a)))
browse()
debug(cachemean)
b <- cachemean(makeVector(a))
b <- cachemean(makeVector(a))
x
m
x$get()
x$getmean()
x$get()
x$getmean()
x$getmean()
m <- NULL
b <- cachemean(makeVector(a))
m
Va <- makeVector(a)
b <- cachemean(Va)
b <- cachemean(Va)
Va@get
Va@get()
Va$get()
Va$getmean()
all.equal(M1,solve(M2))
all.equal(M1,solve(M3))
all.equal(M1,solve(M4))
View(makeVector)
source('~/DataScientist/R-Programming/R Programing Project 2/cachematrix.R')
CM.M1 <- makeCacheMatrix(M1)
CM.M1@get()
CM.M1$get()
CM.M1$getsolve()
M1Inv <- cacheSolve(CM)
M1Inv <- cacheSolve(CM.M1)
M1Inv <- cacheSolve(CM.M1)
M1Inv <- cacheSolve(CM.M1)
M1Inv <- NULL
M1Inv <- cacheSolve(CM.M1)
CM.M1$set(M2)
source('~/DataScientist/R-Programming/R Programing Project 2/cachematrix.R')
CM.M1$set(M2)
source('~/DataScientist/R-Programming/R Programing Project 2/cachematrix.R')
source('~/DataScientist/R-Programming/R Programing Project 2/cachematrix.R')
source('~/DataScientist/R-Programming/R Programing Project 2/cachematrix.R')
M1 <- matrix(c(1,2,2,1,3,5,2,4,5),3,3)
CM.M1 <- makeCacheMatrix(M1)
CM.M1$get()
CM.M1$getsolve()
M1Inv <- cacheSolve(CM.M1)
M1Inv
M1Inv <- cacheSolve(CM.M1)
M1Inv
M1 <- matrix(c(1,2,1,1,5,5,2,4,5),3,3)
M1Inv
M1
CM.M1$set(M1)
CM.M1$getsolve()
M1Inv <- cacheSolve(CM.M1)
M1Inv
rbinom(20,1,0.2)
rbinom(20,1,0.5)
rbinom(20,1,0.8)
set.seed(1)
rpois(5, 2)
set.seed(1)
rpois(5, 2)
set.seed(1)
rpois(5, 2)
set.seed(1)
rpois(5, 2)
x <- 1:10
if(x > 5) {
x <- 0
}
x>5
q()
par("lty")
par("col")
par("pch")
lm(Ozone ~ Wind, airquality)
norm(100)
a <- rnorm(100)
hist(a)
b <- rnorm(100)
plot(a,b)
par(mar = c(2,2,2,2))
plot(a,b)
par(mar = c(4,4,2,2))
plot(a,b)
plot(a,b, pch=19)
plot(a,b, pch=4)
plot(a,b, pch=20)
title(" My Scatter plot")
legend("topleft" pch=20, legenda="data")
legend("topleft" ,pch=20, legenda="data")
legend("topleft" ,pch=20, legend="data")
abline(lm(a,b))
abline(lm(y~z))
abline(lm(b~a))
c <- rnorm(100)
par(mfrow<-c(2,1))
plot(a,b, pch=20)
par(mfrow=c(2,1))
plot(a,b, pch=20)
plot(a,c, pch=20)
par(mfrow=c(2,2))
plot(a,c, pch=20)
plot(a,b, pch=20)
plot(b,c, pch=20)
par(mfrow=c(1,1))
library(swirl)
install_from_swirl("Exploratory Data Analysis")
swirl()
main = "Global Active Power",
source('~/DataScientist/ExploratoryDataA/Project 1/Git/figure/plot1.R')
getwd()
source('~/DataScientist/ExploratoryDataA/Project 1/Git/figure/plot1.R')
setwd("~")
hist(runif(1000))
mns = NULL
for (i in 1 : 1000) mns = c(mns, mean(runif(40)))
hist(mns)
library (swirl)
install_from_swirl("Statistical Inference")
swirl()
1-((2+1)/36)
deck
52
4/52
0
12/52
0
1/51*1/50
(1/51)*(1/50)
(2/51)*(1/50)
(1/51)*(1/50)*2
2/51
q()
date()
setwd("~/DataScientist/ReproResearch/PeerAssessment1")
unzip ("activity.zip")
activityDF <- read.csv("activity.csv")
View(activityDF)
View(activityDF)
strptime(activityDF.date,"%y-%m-%d")
strptime(activityDF$date,"%y-%m-%d")
strptime(as.character(activityDF$date),"%y-%m-%d"))
strptime(as.character(activityDF$date),"%y-%m-%d")[1:5]
as.character(activityDF$date)[1:5]
strptime(as.character(activityDF$date),"%Y-%m-%d")[1:5]
View(activityDF)
View(activityDF)
names(activityDF)
names(activityDF) <- C("1","2","3")
names(activityDF) <- c("1","2","3")
View(activityDF)
View(activityDF)
View(activityDF)
# Downloads the file
url <- "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip"
setInternet2(use = TRUE)
download.file(url, "repdata-data-activity.zip", mode="wb")
# Unzip the activity.zip file available in the working directory on the same directory
unzip ("repdata-data-activity.zip")
# Reads dataset into the activityDF data fame
activityDF <- read.csv("activity.csv")
# TIDY DATA FOR ANALYSIS
# Calculates the POSIXct object variable corresponding to the factor variable date in the dataset to represent datetime
activityDF <- cbind(activityDF,strptime(as.character(activityDF$date),"%Y-%m-%d"))
names(activityDF) <- c("steps","dateAsFactor","interval","date")
# List 5 rows of the data set
activityDF[1:5,]
url <- "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip"
setInternet2(use = TRUE)
download.file(url, "repdata-data-activity.zip", mode="wb")
# Unzip the activity.zip file available in the working directory on the same directory
unzip ("repdata-data-activity.zip")
# Reads dataset into the activityDF data fame
activityDF <- read.csv("activity.csv")
